{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce286915",
   "metadata": {},
   "source": [
    "# LLM Zoomcamp - Module 1 Homework\n",
    "\n",
    "This notebook contains the solutions for the Module 1 homework."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3817d62e",
   "metadata": {},
   "source": [
    "## Setup and Imports\n",
    "\n",
    "First, let's install necessary libraries if you haven't already:\n",
    "```bash\n",
    "pip install requests openai elasticsearch python-dotenv tiktoken tqdm pandas\n",
    "```\n",
    "Ensure you have a `.env` file in the same directory as this notebook (or your OpenAI API key is set as an environment variable):\n",
    "```env\n",
    "OPENAI_API_KEY=\"your_openai_api_key_here\"\n",
    "```\n",
    "And make sure your Elasticsearch instance is running (e.g., using Docker for version 8.17.0 as suggested by the homework context, though the specific version might vary slightly in your setup):\n",
    "```bash\n",
    "docker run -it --rm --name elasticsearch -p 9200:9200 -p 9300:9300 -e \"discovery.type=single-node\" -e \"xpack.security.enabled=false\" docker.elastic.co/elasticsearch/elasticsearch:8.17.0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e2f8300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to Elasticsearch.\n"
     ]
    }
   ],
   "source": [
    "# Common imports and setup for the notebook\n",
    "import requests\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from elasticsearch import Elasticsearch\n",
    "from tqdm.auto import tqdm\n",
    "import tiktoken\n",
    "import pandas as pd\n",
    "\n",
    "# Load environment variables (for OpenAI API key)\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize OpenAI client\n",
    "# Ensure OPENAI_API_KEY is in your .env file or environment\n",
    "try:\n",
    "    client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "    if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "        print(\"Warning: OPENAI_API_KEY not found. OpenAI calls will fail.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing OpenAI client: {e}\")\n",
    "\n",
    "# Initialize Elasticsearch client\n",
    "# Make sure your Elasticsearch instance is running\n",
    "try:\n",
    "    es_client = Elasticsearch('http://localhost:9200')\n",
    "    if not es_client.ping(): # Check connection\n",
    "        raise ConnectionError(\"Failed to connect to Elasticsearch at http://localhost:9200\")\n",
    "    print(\"Successfully connected to Elasticsearch.\")\n",
    "except ConnectionError as e:\n",
    "    print(f\"ConnectionError: {e}. Please ensure Elasticsearch is running and accessible.\")\n",
    "    # You might want to stop execution here or handle it gracefully\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred when connecting to Elasticsearch: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a4b1f0",
   "metadata": {},
   "source": [
    "## Q1: Elasticsearch Version\n",
    "\n",
    "**Goal:** Get the `version.build_hash` from your running Elasticsearch instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7a52fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1 Answer: Elasticsearch version.build_hash: 42f05b9372a9a4a470db3b52817899b99a76ee73\n"
     ]
    }
   ],
   "source": [
    "# Q1: Get Elasticsearch version.build_hash\n",
    "build_hash_q1 = None\n",
    "try:\n",
    "    if es_client.ping(): # Ensure client is connected\n",
    "        info = es_client.info()\n",
    "        build_hash_q1 = info['version']['build_hash']\n",
    "        print(f\"Q1 Answer: Elasticsearch version.build_hash: {build_hash_q1}\")\n",
    "    else:\n",
    "        print(\"Cannot get Elasticsearch info for Q1. Client not connected.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error getting Elasticsearch info for Q1: {e}\")\n",
    "    print(\"Please ensure Elasticsearch (e.g., version 8.17.0) is running and accessible.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef35b2f",
   "metadata": {},
   "source": [
    "## Getting the FAQ Data\n",
    "\n",
    "**Goal:** Fetch the FAQ data from the provided URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5de6ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 948 documents.\n"
     ]
    }
   ],
   "source": [
    "docs_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main/01-intro/documents.json?raw=true'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "for course_data in documents_raw:\n",
    "    course_name = course_data['course']\n",
    "    for doc in course_data['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)\n",
    "\n",
    "print(f\"Successfully loaded {len(documents)} documents.\")\n",
    "# print(documents[0]) # To inspect the first document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9a9452b-5b9a-42fd-b96e-9e13c3bf0af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\", 'section': 'General course-related questions', 'question': 'Course - When will the course start?', 'course': 'data-engineering-zoomcamp'}\n"
     ]
    }
   ],
   "source": [
    "print(documents[0]) # To inspect the first document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913851df",
   "metadata": {},
   "source": [
    "## Q2: Indexing Data\n",
    "\n",
    "**Goal:** Index the fetched FAQ data. `course` field as `keyword`, others as `text`. Identify the function for adding data.\n",
    "\n",
    "**Which function do you use for adding your data to elastic?**\n",
    "* `insert`\n",
    "* **`index`**\n",
    "* `put`\n",
    "* `add`\n",
    "\n",
    "The correct function is `index`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e5f1824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'course-faq-homework-2025' deleted.\n",
      "Index 'course-faq-homework-2025' created.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "651a6a9142ea40289856df5a09ec4a99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/948 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q2: Successfully indexed 948 documents into 'course-faq-homework-2025'.\n",
      "The function used for adding data is 'es_client.index()'.\n"
     ]
    }
   ],
   "source": [
    "# Q2: Indexing data\n",
    "index_name = \"course-faq-homework-2025\"\n",
    "\n",
    "# Define index settings and mappings\n",
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"course\": {\"type\": \"keyword\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"text\": {\"type\": \"text\"}\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "try:\n",
    "    if es_client.indices.exists(index=index_name):\n",
    "        es_client.indices.delete(index=index_name)\n",
    "        print(f\"Index '{index_name}' deleted.\")\n",
    "    es_client.indices.create(index=index_name, body=index_settings)\n",
    "    print(f\"Index '{index_name}' created.\")\n",
    "\n",
    "    # Index the documents\n",
    "    for doc in tqdm(documents):\n",
    "        es_client.index(index=index_name, document=doc)\n",
    "    print(f\"Q2: Successfully indexed {len(documents)} documents into '{index_name}'.\")\n",
    "    print(\"The function used for adding data is 'es_client.index()'.\")\n",
    "\n",
    "except ConnectionError:\n",
    "    print(\"Elasticsearch connection error for Q2. Cannot perform indexing.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during indexing for Q2: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb83f43",
   "metadata": {},
   "source": [
    "## Q3: Searching with Boost\n",
    "\n",
    "**Goal:** Query \"How do execute a command on a Kubernetes pod?\". Use `question` (boost 4) and `text` fields. Type `best_fields`. Find the top score.\n",
    "\n",
    "Options:\n",
    "* 84.50\n",
    "* 64.50\n",
    "* 44.50\n",
    "* 24.50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccbfed43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q3 Answer: The score for the top ranking result is: 44.50556\n"
     ]
    }
   ],
   "source": [
    "# Q3: Searching with boost\n",
    "query_q3 = \"How do execute a command on a Kubernetes pod?\"\n",
    "score_q3_answer = None\n",
    "\n",
    "search_query_q3 = {\n",
    "    \"size\": 1, \n",
    "    \"query\": {\n",
    "        \"multi_match\": {\n",
    "            \"query\": query_q3,\n",
    "            \"fields\": [\"question^4\", \"text\"], \n",
    "            \"type\": \"best_fields\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "try:\n",
    "    response_q3 = es_client.search(index=index_name, body=search_query_q3)\n",
    "    if response_q3['hits']['hits']:\n",
    "        top_hit_q3 = response_q3['hits']['hits'][0]\n",
    "        score_q3_answer = top_hit_q3['_score']\n",
    "        print(f\"Q3 Answer: The score for the top ranking result is: {score_q3_answer}\")\n",
    "    else:\n",
    "        print(f\"No results found for the query in Q3: '{query_q3}'\")\n",
    "except ConnectionError:\n",
    "    print(\"Elasticsearch connection error for Q3. Cannot perform search.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during search Q3: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc31f13",
   "metadata": {},
   "source": [
    "## Q4: Filtered Search\n",
    "\n",
    "**Goal:** Query \"How do copy a file to a Docker container?\". Filter for `machine-learning-zoomcamp`. Return 3 results. Identify the 3rd question.\n",
    "\n",
    "Options:\n",
    "* How do I debug a docker container?\n",
    "* How do I copy files from a different folder into docker container’s working directory?\n",
    "* How do Lambda container images work?\n",
    "* How can I annotate a graph?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a9a9b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q4 Answer: The 3rd question returned is: 'How do I debug a docker container?'\n"
     ]
    }
   ],
   "source": [
    "# Q4: Filtered search\n",
    "query_q4 = \"How do copy a file to a Docker container?\"\n",
    "course_filter_q4 = \"machine-learning-zoomcamp\"\n",
    "third_question_q4_answer = None\n",
    "\n",
    "search_query_q4 = {\n",
    "    \"size\": 3, \n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"must\": {\n",
    "                \"multi_match\": {\n",
    "                    \"query\": query_q4,\n",
    "                    \"fields\": [\"question\", \"text\"],\n",
    "                    \"type\": \"best_fields\"\n",
    "                }\n",
    "            },\n",
    "            \"filter\": {\n",
    "                \"term\": {\n",
    "                    \"course\": course_filter_q4\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "retrieved_hits_q4_for_q5_context = [] # Store for Q5\n",
    "try:\n",
    "    response_q4 = es_client.search(index=index_name, body=search_query_q4)\n",
    "    retrieved_hits_q4_for_q5_context = response_q4['hits']['hits'] # Save for Q5\n",
    "    \n",
    "    if len(retrieved_hits_q4_for_q5_context) >= 3:\n",
    "        third_question_q4_answer = retrieved_hits_q4_for_q5_context[2]['_source']['question']\n",
    "        print(f\"Q4 Answer: The 3rd question returned is: '{third_question_q4_answer}'\")\n",
    "    elif len(retrieved_hits_q4_for_q5_context) > 0:\n",
    "        print(f\"Only {len(retrieved_hits_q4_for_q5_context)} results returned for Q4. Cannot get the 3rd question.\")\n",
    "    else:\n",
    "        print(\"No results returned for the query in Q4.\")\n",
    "\n",
    "except ConnectionError:\n",
    "    print(\"Elasticsearch connection error for Q4. Cannot perform search.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during search Q4: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "661a7262-e1f8-4090-a9bf-796c5cc488b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(retrieved_hits_q4_for_q5_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "302a7e3b-0b9a-4e16-9b7b-dff458908319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_index': 'course-faq-homework-2025',\n",
       " '_id': 'l317IpcBSJ5i86OCcivc',\n",
       " '_score': 22.931826,\n",
       " '_source': {'text': \"You can copy files from your local machine into a Docker container using the docker cp command. Here's how to do it:\\nTo copy a file or directory from your local machine into a running Docker container, you can use the `docker cp command`. The basic syntax is as follows:\\ndocker cp /path/to/local/file_or_directory container_id:/path/in/container\\nHrithik Kumar Advani\",\n",
       "  'section': '5. Deploying Machine Learning Models',\n",
       "  'question': 'How do I copy files from my local machine to docker container?',\n",
       "  'course': 'machine-learning-zoomcamp'}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_hits_q4_for_q5_context[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0bdb2403-5f0a-4b6c-8054-cda2df5a65d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_index': 'course-faq-homework-2025',\n",
       "  '_id': 'l317IpcBSJ5i86OCcivc',\n",
       "  '_score': 22.931826,\n",
       "  '_source': {'text': \"You can copy files from your local machine into a Docker container using the docker cp command. Here's how to do it:\\nTo copy a file or directory from your local machine into a running Docker container, you can use the `docker cp command`. The basic syntax is as follows:\\ndocker cp /path/to/local/file_or_directory container_id:/path/in/container\\nHrithik Kumar Advani\",\n",
       "   'section': '5. Deploying Machine Learning Models',\n",
       "   'question': 'How do I copy files from my local machine to docker container?',\n",
       "   'course': 'machine-learning-zoomcamp'}},\n",
       " {'_index': 'course-faq-homework-2025',\n",
       "  '_id': 'mH17IpcBSJ5i86OCcivd',\n",
       "  '_score': 19.161318,\n",
       "  '_source': {'text': 'You can copy files from your local machine into a Docker container using the docker cp command. Here\\'s how to do it:\\nIn the Dockerfile, you can provide the folder containing the files that you want to copy over. The basic syntax is as follows:\\nCOPY [\"src/predict.py\", \"models/xgb_model.bin\", \"./\"]\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tGopakumar Gopinathan',\n",
       "   'section': '5. Deploying Machine Learning Models',\n",
       "   'question': 'How do I copy files from a different folder into docker container’s working directory?',\n",
       "   'course': 'machine-learning-zoomcamp'}},\n",
       " {'_index': 'course-faq-homework-2025',\n",
       "  '_id': 'eH17IpcBSJ5i86OCciuc',\n",
       "  '_score': 18.34669,\n",
       "  '_source': {'text': 'Launch the container image in interactive mode and overriding the entrypoint, so that it starts a bash command.\\ndocker run -it --entrypoint bash <image>\\nIf the container is already running, execute a command in the specific container:\\ndocker ps (find the container-id)\\ndocker exec -it <container-id> bash\\n(Marcos MJD)',\n",
       "   'section': '5. Deploying Machine Learning Models',\n",
       "   'question': 'How do I debug a docker container?',\n",
       "   'course': 'machine-learning-zoomcamp'}}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_hits_q4_for_q5_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43064707-1959-4c18-8243-78909c162d97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You can copy files from your local machine into a Docker container using the docker cp command. Here's how to do it:\\nTo copy a file or directory from your local machine into a running Docker container, you can use the `docker cp command`. The basic syntax is as follows:\\ndocker cp /path/to/local/file_or_directory container_id:/path/in/container\\nHrithik Kumar Advani\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_hits_q4_for_q5_context[0][\"_source\"][\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05991e0d",
   "metadata": {},
   "source": [
    "## Q5: Building a Prompt\n",
    "\n",
    "**Goal:** Use records from Q4 to build context. Use this context and question \"How do I execute a command in a running docker container?\" to construct a prompt. Find the prompt's length.\n",
    "\n",
    "Prompt Template for Context Entries:\n",
    "```\n",
    "Q: {question}\n",
    "A: {text}\n",
    "```\n",
    "Main Prompt Template:\n",
    "```\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "```\n",
    "Options for length:\n",
    "* 946\n",
    "* 1446\n",
    "* 1946\n",
    "* 2446"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eeb0367c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q5 Answer: The length of the resulting prompt is: 1462\n"
     ]
    }
   ],
   "source": [
    "# Q5: Building a prompt and calculating its length\n",
    "final_prompt_q5_text = None\n",
    "prompt_length_q5_answer = None\n",
    "\n",
    "context_docs_q5 = []\n",
    "if 'retrieved_hits_q4_for_q5_context' in locals() and retrieved_hits_q4_for_q5_context:\n",
    "    for hit in retrieved_hits_q4_for_q5_context:\n",
    "        context_docs_q5.append(hit['_source'])\n",
    "else:\n",
    "    print(\"Warning for Q5: Context from Q4 not available. Retrieving again.\")\n",
    "    # This is a fallback, ideally Q4 should populate retrieved_hits_q4_for_q5_context\n",
    "    try:\n",
    "        response_q4_fallback = es_client.search(index=index_name, body=search_query_q4) # Uses search_query_q4\n",
    "        retrieved_hits_q4_for_q5_context = response_q4_fallback['hits']['hits']\n",
    "        for hit in retrieved_hits_q4_for_q5_context:\n",
    "            context_docs_q5.append(hit['_source'])\n",
    "    except Exception as e:\n",
    "        print(f\"Error in Q5 fallback context retrieval: {e}\")\n",
    "\n",
    "context_string_q5 = \"\"\n",
    "if context_docs_q5:\n",
    "    for doc in context_docs_q5:\n",
    "        context_entry = f\"Q: {doc.get('question', '')}\\nA: {doc.get('text', '')}\"\n",
    "        context_string_q5 += context_entry.strip() + \"\\n\\n\"\n",
    "context_string_q5 = context_string_q5.strip()\n",
    "# print(\"Context for Q5:\\n\", context_string_q5) # For debugging\n",
    "\n",
    "question_for_prompt_q5 = \"How do I execute a command in a running docker container?\"\n",
    "prompt_template_q5 = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "if context_string_q5: # Only build prompt if context is available\n",
    "    final_prompt_q5_text = prompt_template_q5.format(question=question_for_prompt_q5, context=context_string_q5)\n",
    "    # print(\"\\nFinal Prompt for Q5:\\n\", final_prompt_q5_text) # For debugging\n",
    "    prompt_length_q5_answer = len(final_prompt_q5_text)\n",
    "    print(f\"Q5 Answer: The length of the resulting prompt is: {prompt_length_q5_answer}\")\n",
    "else:\n",
    "    print(\"Could not build prompt for Q5 as context is empty.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e375c09-77ca-4905-b946-db63991ff953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You\\'re a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\\nUse only the facts from the CONTEXT when answering the QUESTION.\\n\\nQUESTION: How do I execute a command in a running docker container?\\n\\nCONTEXT:\\nQ: How do I copy files from my local machine to docker container?\\nA: You can copy files from your local machine into a Docker container using the docker cp command. Here\\'s how to do it:\\nTo copy a file or directory from your local machine into a running Docker container, you can use the `docker cp command`. The basic syntax is as follows:\\ndocker cp /path/to/local/file_or_directory container_id:/path/in/container\\nHrithik Kumar Advani\\n\\nQ: How do I copy files from a different folder into docker container’s working directory?\\nA: You can copy files from your local machine into a Docker container using the docker cp command. Here\\'s how to do it:\\nIn the Dockerfile, you can provide the folder containing the files that you want to copy over. The basic syntax is as follows:\\nCOPY [\"src/predict.py\", \"models/xgb_model.bin\", \"./\"]\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tGopakumar Gopinathan\\n\\nQ: How do I debug a docker container?\\nA: Launch the container image in interactive mode and overriding the entrypoint, so that it starts a bash command.\\ndocker run -it --entrypoint bash <image>\\nIf the container is already running, execute a command in the specific container:\\ndocker ps (find the container-id)\\ndocker exec -it <container-id> bash\\n(Marcos MJD)'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_prompt_q5_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a08cda",
   "metadata": {},
   "source": [
    "## Q6: Token Counting\n",
    "\n",
    "**Goal:** Calculate the number of tokens in the Q5 prompt using `tiktoken`.\n",
    "\n",
    "Options:\n",
    "* 120\n",
    "* 220\n",
    "* 320\n",
    "* 420"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41090705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q6 Answer: The number of tokens in the prompt from Q5 is: 323\n"
     ]
    }
   ],
   "source": [
    "# Q6: Token counting\n",
    "num_tokens_q6_answer = None\n",
    "\n",
    "if final_prompt_q5_text:\n",
    "    try:\n",
    "        encoding = tiktoken.encoding_for_model(\"gpt-4o\") # As per homework context\n",
    "        num_tokens_q6_answer = len(encoding.encode(final_prompt_q5_text))\n",
    "        print(f\"Q6 Answer: The number of tokens in the prompt from Q5 is: {num_tokens_q6_answer}\")\n",
    "        \n",
    "        # Example of decoding a token (not part of the answer, just for illustration)\n",
    "        # if num_tokens_q6_answer > 0:\n",
    "        #     first_token = encoding.encode(final_prompt_q5_text)[0]\n",
    "        #     decoded_token_bytes = encoding.decode_single_token_bytes(first_token)\n",
    "        #     print(f\"Example: First token ID: {first_token}, Decoded bytes: {decoded_token_bytes}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during token counting for Q6: {e}\")\n",
    "else:\n",
    "    print(\"Prompt from Q5 (final_prompt_q5_text) is not available for Q6 token counting.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0814f16f",
   "metadata": {},
   "source": [
    "## Q7: OpenAI Response\n",
    "\n",
    "**Goal:** Send the Q5 prompt to OpenAI. What's the response?\n",
    "\n",
    "*Note: This requires a valid OpenAI API key and will incur a small cost.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34c82eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending prompt (length: 1462 chars, approx tokens: 323) to OpenAI for Q7...\n",
      "Q7 Response from OpenAI:\n",
      "To execute a command in a running Docker container, use the `docker exec` command. First, you can find the container ID by using `docker ps` to list all running containers. Then, execute your desired command in the container using the following syntax:\n",
      "\n",
      "```\n",
      "docker exec -it <container-id> <command>\n",
      "```\n",
      "\n",
      "For example, to open a bash shell, you would use:\n",
      "\n",
      "```\n",
      "docker exec -it <container-id> bash\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# Q7: Send prompt to OpenAI and get response\n",
    "openai_answer_q7 = \"Error: Prerequisite prompt not available or API call failed.\"\n",
    "\n",
    "if final_prompt_q5_text:\n",
    "    print(f\"Sending prompt (length: {len(final_prompt_q5_text)} chars, approx tokens: {num_tokens_q6_answer if num_tokens_q6_answer else 'N/A'}) to OpenAI for Q7...\")\n",
    "    try:\n",
    "        if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "            print(\"OPENAI_API_KEY not set. Skipping Q7 API call.\")\n",
    "            openai_answer_q7 = \"Skipped: OPENAI_API_KEY not set.\"\n",
    "        else:\n",
    "            openai_response_q7 = client.chat.completions.create(\n",
    "                model=\"gpt-4o\", # As per homework context for pricing\n",
    "                messages=[{\"role\": \"user\", \"content\": final_prompt_q5_text}]\n",
    "            )\n",
    "            openai_answer_q7 = openai_response_q7.choices[0].message.content\n",
    "            print(\"Q7 Response from OpenAI:\")\n",
    "            print(openai_answer_q7)\n",
    "    except NameError as e:\n",
    "        print(f\"Cannot proceed with Q7: {e} - ensure final_prompt_q5_text is defined.\")\n",
    "        openai_answer_q7 = f\"Error: {e}\"\n",
    "    except openai.APIConnectionError as e:\n",
    "        print(f\"OpenAI API Connection Error for Q7: {e}\")\n",
    "        openai_answer_q7 = f\"OpenAI API Connection Error: {e}\"\n",
    "    except openai.RateLimitError as e:\n",
    "        print(f\"OpenAI API Rate Limit Error for Q7: {e}\")\n",
    "        openai_answer_q7 = f\"OpenAI API Rate Limit Error: {e}\"\n",
    "    except openai.APIStatusError as e:\n",
    "        print(f\"OpenAI API Status Error for Q7: {e.status_code} - {e.response}\")\n",
    "        openai_answer_q7 = f\"OpenAI API Status Error: {e.status_code}\"\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred with OpenAI API call for Q7: {e}\")\n",
    "        openai_answer_q7 = f\"Unexpected OpenAI API error: {e}\"\n",
    "else:\n",
    "    print(\"Prompt from Q5 (final_prompt_q5_text) is not available. Skipping Q7 OpenAI call.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf5fa79",
   "metadata": {},
   "source": [
    "## Q8: Cost Calculation\n",
    "\n",
    "**Goal:** Calculate the cost for 1000 requests with average 150 input tokens and 250 output tokens per request.\n",
    "Prices for gpt-4o (June 17):\n",
    "* Input: $0.005 / 1K tokens\n",
    "* Output: $0.015 / 1K tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2fc83164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total input tokens for 1000 requests: 150000\n",
      "Total output tokens for 1000 requests: 250000\n",
      "Cost for input tokens: $0.75\n",
      "Cost for output tokens: $3.75\n",
      "Q8 Answer: Total estimated cost for 1000 requests: $4.50\n"
     ]
    }
   ],
   "source": [
    "# Q8: Cost calculation\n",
    "\n",
    "avg_input_tokens_per_request = 150\n",
    "avg_output_tokens_per_request = 250\n",
    "num_requests = 1000\n",
    "\n",
    "price_input_per_1k_tokens = 0.005  # dollars\n",
    "price_output_per_1k_tokens = 0.015 # dollars\n",
    "\n",
    "total_input_tokens = avg_input_tokens_per_request * num_requests\n",
    "total_output_tokens = avg_output_tokens_per_request * num_requests\n",
    "\n",
    "cost_input = (total_input_tokens / 1000) * price_input_per_1k_tokens\n",
    "cost_output = (total_output_tokens / 1000) * price_output_per_1k_tokens\n",
    "\n",
    "total_cost_q8_answer = cost_input + cost_output\n",
    "\n",
    "print(f\"Total input tokens for {num_requests} requests: {total_input_tokens}\")\n",
    "print(f\"Total output tokens for {num_requests} requests: {total_output_tokens}\")\n",
    "print(f\"Cost for input tokens: ${cost_input:.2f}\")\n",
    "print(f\"Cost for output tokens: ${cost_output:.2f}\")\n",
    "print(f\"Q8 Answer: Total estimated cost for {num_requests} requests: ${total_cost_q8_answer:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5c5a87",
   "metadata": {},
   "source": [
    "### Bonus: Re-calculate cost with Q6 and Q7 values (if available)\n",
    "\n",
    "This is an optional step to apply the pricing to the actual tokens used in Q6 (prompt) and Q7 (response)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd176fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PRICES AS OF JUNE 2024):\n",
      "\n",
      "Bonus Calculation (based on Q6 prompt and Q7 response):\n",
      "  Actual input tokens (Q6 prompt): 323\n",
      "  Actual output tokens (Q7 response): 93\n",
      "  Cost for actual input: $0.001615\n",
      "  Cost for actual output: $0.001395\n",
      "  Total cost for the single Q6/Q7 RAG call: $0.003010\n"
     ]
    }
   ],
   "source": [
    "# Bonus: Cost calculation based on Q6 and Q7 actuals\n",
    "cost_bonus = None\n",
    "if num_tokens_q6_answer is not None and openai_answer_q7 and not openai_answer_q7.startswith(\"Error\") and not openai_answer_q7.startswith(\"Skipped\"):\n",
    "    try:\n",
    "        actual_input_tokens = num_tokens_q6_answer\n",
    "        actual_output_tokens = len(encoding.encode(openai_answer_q7)) # Assuming 'encoding' is still defined from Q6\n",
    "        \n",
    "        cost_input_actual = (actual_input_tokens / 1000) * price_input_per_1k_tokens\n",
    "        cost_output_actual = (actual_output_tokens / 1000) * price_output_per_1k_tokens\n",
    "        cost_bonus = cost_input_actual + cost_output_actual\n",
    "\n",
    "        print(f\"\\nPRICES AS OF JUNE 2024):\")\n",
    "        print(f\"\\nBonus Calculation (based on Q6 prompt and Q7 response):\")\n",
    "        print(f\"  Actual input tokens (Q6 prompt): {actual_input_tokens}\")\n",
    "        print(f\"  Actual output tokens (Q7 response): {actual_output_tokens}\")\n",
    "        print(f\"  Cost for actual input: ${cost_input_actual:.6f}\")\n",
    "        print(f\"  Cost for actual output: ${cost_output_actual:.6f}\")\n",
    "        print(f\"  Total cost for the single Q6/Q7 RAG call: ${cost_bonus:.6f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in bonus cost calculation: {e}\")\n",
    "else:\n",
    "    print(\"\\nBonus Calculation: Skipped, as actual token counts from Q6/Q7 are not available or Q7 failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88db44ac-d4f1-4b9b-8477-55004a065e6b",
   "metadata": {},
   "source": [
    "as june 2024\n",
    "Bonus Calculation (based on Q6 prompt and Q7 response):\n",
    "  Actual input tokens (Q6 prompt): 323\n",
    "  Actual output tokens (Q7 response): 85\n",
    "  Cost for actual input: $0.001615\n",
    "  Cost for actual output: $0.001275\n",
    "  Total cost for the single Q6/Q7 RAG call: $0.002890"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a731f4a-6958-40a0-8fda-709ab56fc7fc",
   "metadata": {},
   "source": [
    "as may 2025 con 4o\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffce3edb-ba6d-4bff-b013-1e7963e651de",
   "metadata": {},
   "source": [
    "gpt-4o\n",
    "gpt-4o-2024-08-06\n",
    "\t\n",
    "$2.50\n",
    "\t\n",
    "$1.25\n",
    "\t\n",
    "$10.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e4792ff-6d40-4cd9-894c-87102390fc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_input_per_1k_tokens_4o = 2.5/1000  # dollars\n",
    "price_output_per_1k_tokens_4o = 10/1000 # dollars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c81eab8-5aec-4837-9f23-973c0faed911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PRICES AS OF MAY 2025):\n",
      "\n",
      "Bonus Calculation (based on Q6 prompt and Q7 response):\n",
      "  Actual input tokens (Q6 prompt): 323\n",
      "  Actual output tokens (Q7 response): 93\n",
      "  Cost for actual input: $0.000807500\n",
      "  Cost for actual output: $0.000930000\n",
      "  Total cost for the single Q6/Q7 RAG call: $0.001737500\n"
     ]
    }
   ],
   "source": [
    "# Bonus: Cost calculation based on Q6 and Q7 actuals\n",
    "cost_bonus = None\n",
    "if num_tokens_q6_answer is not None and openai_answer_q7 and not openai_answer_q7.startswith(\"Error\") and not openai_answer_q7.startswith(\"Skipped\"):\n",
    "    try:\n",
    "        actual_input_tokens = num_tokens_q6_answer\n",
    "        actual_output_tokens = len(encoding.encode(openai_answer_q7)) # Assuming 'encoding' is still defined from Q6\n",
    "        \n",
    "        cost_input_actual = (actual_input_tokens / 1000) * price_input_per_1k_tokens_4o\n",
    "        cost_output_actual = (actual_output_tokens / 1000) * price_output_per_1k_tokens_4o\n",
    "        cost_bonus = cost_input_actual + cost_output_actual\n",
    "\n",
    "        print(f\"\\nPRICES AS OF MAY 2025):\")\n",
    "        \n",
    "        print(f\"\\nBonus Calculation (based on Q6 prompt and Q7 response):\")\n",
    "        print(f\"  Actual input tokens (Q6 prompt): {actual_input_tokens}\")\n",
    "        print(f\"  Actual output tokens (Q7 response): {actual_output_tokens}\")\n",
    "        print(f\"  Cost for actual input: ${cost_input_actual:.9f}\")\n",
    "        print(f\"  Cost for actual output: ${cost_output_actual:.9f}\")\n",
    "        print(f\"  Total cost for the single Q6/Q7 RAG call: ${cost_bonus:.9f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error in bonus cost calculation: {e}\")\n",
    "else:\n",
    "    print(\"\\nBonus Calculation: Skipped, as actual token counts from Q6/Q7 are not available or Q7 failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e74c8b-2c93-44f1-90d3-33ed4e2841ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4af353-e1a5-401d-9de6-e57a96fe95e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python_3.10.12(.env_dataeng)",
   "language": "python",
   "name": ".env_dataeng"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
